{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPO0uo0XdEpKfEccukIVEHY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tibalesut/test_2/blob/main/DL1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ndjt24OBx8J",
        "outputId": "1155beb7-3220-4bc4-925f-9f55d3c6d319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 27 14:49:10 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "_CMjxS-7CCYA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vUO1gLstCUaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping, stacking, queezing and unsqueezing tensors\n",
        "\n",
        "* Reshaping - reshapes an input tensor to a defined shape\n",
        "* View - return a view of an input tensor of a certain shape but keep the same memory as the original tensor\n",
        "* Stacking - combine multiple tensors on top of each other, V or H stack\n",
        "* Squeeze - whch removes all '1' dimensions from a tensor\n",
        "* Unsqueeze -add a '1' diminesion to a traget tensor\n",
        "* Permute - return a view of the imput with dimensions permuted (swapped) in a certain way.\n"
      ],
      "metadata": {
        "id": "oBxSeU13C8N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a tensor\n",
        "x = torch.arange(1., 10.)\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j6ZyYi7EAV4",
        "outputId": "21744f9e-ff4d-48ce-931d-6df2004d007b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra dimension, reshape has to be compatible with the original size\n",
        "# x_reshaped = x.reshape(1, 7)  # invalid because squeeze 9 element into 7\n",
        "# x_reshaped = x.reshape(2, 9)  # invalid because because 2 times 9 is 18, we trying to double the number of elements\n",
        "x_reshaped = x.reshape(9, 1)\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqqiLKlwEQBK",
        "outputId": "b7b48bbf-9d75-4e6f-9ac0-97a908807dba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.],\n",
              "         [2.],\n",
              "         [3.],\n",
              "         [4.],\n",
              "         [5.],\n",
              "         [6.],\n",
              "         [7.],\n",
              "         [8.],\n",
              "         [9.]]),\n",
              " torch.Size([9, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_reshaped = x.reshape(1,9)\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rozOrNWpGDdN",
        "outputId": "abb63d6c-89c6-49fb-b4f0-a902b264a2e9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change the view\n",
        "z = x.view(1, 9)  # shares the memory of the original tensor\n",
        "z, z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r65dSkOOGr-C",
        "outputId": "5baa7215-7677-4101-e3b0-d634b9a92640"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing z changes x (a view of a tensor shares the same memory as the original)\n",
        "z[:, 0] = 5\n",
        "z, x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6Lq5505HAo0",
        "outputId": "bf06b1cf-a9db-4410-beb8-09d2c2463363"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
              " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stack tensor on top of each other\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
        "x_stacked, x_stacked.shape  # stacks verticaly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dR4Pw54HS56",
        "outputId": "9103ce62-5d5b-495e-f7a6-9a3da34e3d7a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "         [5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
              " torch.Size([4, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stack tensor on top of each other\n",
        "x_stacked = torch.stack([x, x, x, x], dim=1)\n",
        "x_stacked, x_stacked.shape  # stacks horizontaly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHMUF48JHtNN",
        "outputId": "43bf07d4-eda7-4748-e5db-ab309762f596"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 5., 5., 5.],\n",
              "         [2., 2., 2., 2.],\n",
              "         [3., 3., 3., 3.],\n",
              "         [4., 4., 4., 4.],\n",
              "         [5., 5., 5., 5.],\n",
              "         [6., 6., 6., 6.],\n",
              "         [7., 7., 7., 7.],\n",
              "         [8., 8., 8., 8.],\n",
              "         [9., 9., 9., 9.]]),\n",
              " torch.Size([9, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}